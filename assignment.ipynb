{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data preproccesing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>short_description</th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffpost.com/entry/funniest-tweets...</td>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>COMEDY</td>\n",
       "      <td>\"Until you have a dog you don't understand wha...</td>\n",
       "      <td>Elyse Wanshel</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffpost.com/entry/funniest-parent...</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "      <td>PARENTING</td>\n",
       "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
       "      <td>Caroline Bologna</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.huffpost.com/entry/dodgers-basebal...</td>\n",
       "      <td>Maury Wills, Base-Stealing Shortstop For Dodge...</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>Maury Wills, who helped the Los Angeles Dodger...</td>\n",
       "      <td>Beth Harris, AP</td>\n",
       "      <td>2022-09-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.huffpost.com/entry/golden-globes-r...</td>\n",
       "      <td>Golden Globes Returning To NBC In January Afte...</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>For the past 18 months, Hollywood has effectiv...</td>\n",
       "      <td></td>\n",
       "      <td>2022-09-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffpost.com/entry/biden-us-forces...</td>\n",
       "      <td>Biden Says U.S. Forces Would Defend Taiwan If ...</td>\n",
       "      <td>POLITICS</td>\n",
       "      <td>President issues vow as tensions with China rise.</td>\n",
       "      <td></td>\n",
       "      <td>2022-09-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://www.huffpost.com/entry/funniest-tweets...   \n",
       "1  https://www.huffpost.com/entry/funniest-parent...   \n",
       "2  https://www.huffpost.com/entry/dodgers-basebal...   \n",
       "3  https://www.huffpost.com/entry/golden-globes-r...   \n",
       "4  https://www.huffpost.com/entry/biden-us-forces...   \n",
       "\n",
       "                                            headline       category  \\\n",
       "0  23 Of The Funniest Tweets About Cats And Dogs ...         COMEDY   \n",
       "1  The Funniest Tweets From Parents This Week (Se...      PARENTING   \n",
       "2  Maury Wills, Base-Stealing Shortstop For Dodge...         SPORTS   \n",
       "3  Golden Globes Returning To NBC In January Afte...  ENTERTAINMENT   \n",
       "4  Biden Says U.S. Forces Would Defend Taiwan If ...       POLITICS   \n",
       "\n",
       "                                   short_description           authors  \\\n",
       "0  \"Until you have a dog you don't understand wha...     Elyse Wanshel   \n",
       "1  \"Accidentally put grown-up toothpaste on my to...  Caroline Bologna   \n",
       "2  Maury Wills, who helped the Los Angeles Dodger...   Beth Harris, AP   \n",
       "3  For the past 18 months, Hollywood has effectiv...                     \n",
       "4  President issues vow as tensions with China rise.                     \n",
       "\n",
       "        date  \n",
       "0 2022-09-23  \n",
       "1 2022-09-23  \n",
       "2 2022-09-20  \n",
       "3 2022-09-20  \n",
       "4 2022-09-19  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json('News_Category_Dataset_IS_course.json', lines=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Understanding the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BLACK VOICES',\n",
       " 'BUSINESS',\n",
       " 'COMEDY',\n",
       " 'ENTERTAINMENT',\n",
       " 'FOOD & DRINK',\n",
       " 'HEALTHY LIVING',\n",
       " 'HOME & LIVING',\n",
       " 'PARENTING',\n",
       " 'PARENTS',\n",
       " 'POLITICS',\n",
       " 'QUEER VOICES',\n",
       " 'SPORTS',\n",
       " 'STYLE & BEAUTY',\n",
       " 'TRAVEL',\n",
       " 'WELLNESS']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = data.groupby('category').size().index.tolist()\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there null elements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "link                   0\n",
       "headline             731\n",
       "category               0\n",
       "short_description    736\n",
       "authors                0\n",
       "date                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#is there a row where the short_description is null and headline is null?\n",
    "len(data[(data['short_description'].isnull()) & (data['headline'].isnull())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24416"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many rows have authors ''?\n",
    "len(data[data['authors'] == ''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we don't need link,authors and date we drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['link', 'authors', 'date'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine headline and short_description and save it as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if headline is null use add only  short_description and vice versa\n",
    "data['text'] = data.apply(lambda row: row['short_description'] if pd.isnull(row['headline']) else row['headline'], axis=1)\n",
    "data = data.drop(['headline', 'short_description'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COMEDY</td>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PARENTING</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>Maury Wills, Base-Stealing Shortstop For Dodge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Golden Globes Returning To NBC In January Afte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POLITICS</td>\n",
       "      <td>Biden Says U.S. Forces Would Defend Taiwan If ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148117</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>'Girl With the Dragon Tattoo' India Release Ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148118</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>Maria Sharapova Stunned By Victoria Azarenka I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148119</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>Giants Over Patriots, Jets Over Colts Among  M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148120</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>Aldon Smith Arrested: 49ers Linebacker Busted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148121</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>Dwight Howard Rips Teammates After Magic Loss ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148122 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             category                                               text\n",
       "0              COMEDY  23 Of The Funniest Tweets About Cats And Dogs ...\n",
       "1           PARENTING  The Funniest Tweets From Parents This Week (Se...\n",
       "2              SPORTS  Maury Wills, Base-Stealing Shortstop For Dodge...\n",
       "3       ENTERTAINMENT  Golden Globes Returning To NBC In January Afte...\n",
       "4            POLITICS  Biden Says U.S. Forces Would Defend Taiwan If ...\n",
       "...               ...                                                ...\n",
       "148117  ENTERTAINMENT  'Girl With the Dragon Tattoo' India Release Ca...\n",
       "148118         SPORTS  Maria Sharapova Stunned By Victoria Azarenka I...\n",
       "148119         SPORTS  Giants Over Patriots, Jets Over Colts Among  M...\n",
       "148120         SPORTS  Aldon Smith Arrested: 49ers Linebacker Busted ...\n",
       "148121         SPORTS  Dwight Howard Rips Teammates After Magic Loss ...\n",
       "\n",
       "[148122 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from IPython.display import clear_output\n",
    "import inflect\n",
    "\n",
    "# Download necessary resources (if not already downloaded)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Initialize inflect engine\n",
    "p = inflect.engine()\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`clean_text` function transforms the text to lower case, separates the words as tokens, removes punctuations and stopwords and applies lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "\n",
    "    # Transform to lower case\n",
    "    text = text.lower()\n",
    "\n",
    "    # Transform numbers into words\n",
    "    #words = [p.number_to_words(word) if word.isdigit() else word for word in words]\n",
    "\n",
    "    # Tokenization\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Remove punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    words = [word.translate(table) for word in words if word.isalpha()]\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    #can try stemming? mabye later\n",
    "\n",
    "    # Join the words back into a string\n",
    "    preprocessed_text = ' '.join(lemmatized_words)\n",
    "\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_text'] = data['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
